[[Japanese Homepage]](index_jp.md)

# About
- Hitoshi Nishimura
- Ph.D. (Informatics)
- Core Researcher at KDDI Research, Inc.
- ht-nishimura [at] kddi.com

# News
- 2023/11/14 Our paper was selected as a best paper award of FIT2023.
- 2023/09/22 Our paper was accepted to VCIP2023.
- 2023/06/21 Our paper was accepted to ICIP2023.

# Research
- Computer Vision (Object Tracking, Human Action Recognition)
- Compression (2D Video Compression, 3D Mesh Compression)

# Education
- 2018.10-2021.03: Ph.D. in Nagoya University (Early completion)
- 2013.04-2015.03: M.S in Kobe University
- 2009.04-2013.03: B.S in Kobe University

# Work Experience
- 2023.04-now: Tsukuba University
- 2016.04-now: KDDI Research, Inc.
- 2015.04-2016.03: KDDI CORPORATION

# Committee
- 2023.09-now: Vice Chairperson, Publication department, SSII2024
- 2023.04-now: Comittee, AVM, IPSJ
- 2022.06-now: Associate Editor, ITE Journal, ITE
- 2022.06-2023.05: Chairperson, Overseas literature department, ITE
- 2021.06-2022.05: Vice Chairperson, Overseas literature department, ITE
- 2018.06-2022.06: Committee, PRMU, IEICE

# Awards
- Funai best paper award, FIT, 2023. [[link]](https://www.ipsj.or.jp/award/funai_best-paper.html)
- Excellent basic research award of the year, KDDI Research, 2020.
- Best paper of the year, ITE, 2020. [[link]](https://www.ite.or.jp/content/awards/)

# Publications
## Journal
1. <u>H. Nishimura</u>, S. Komorita, Y. Kawanishi, and H. Murase,
“SDOF-Tracker: Fast and Accurate Multiple Human Tracking by Skipped-Detection and Optical-Flow,”
IEICE-ED, 2022. [paper] [[code]](https://github.com/hitottiez/sdof-tracker)
1. <u>H. Nishimura</u>, K. Tasaka, Y. Kawanishi, and H. Murase,
“Multiple Human Tracking with Alternately Updating Trajectories and Multi-Frame Action Features,”
ITE-MTA, 2020. [[paper]](https://www.jstage.jst.go.jp/article/mta/8/4/8_269/_pdf/-char/en) [[code]](https://github.com/hitottiez/mht-paf)
1. <u>H. Nishimura</u>, N. Makibuchi, K. Tasaka, Y. Kawanishi, and H. Murase,
“Multiple Human Tracking using an Omnidirectional Camera with Local Rectification and World Coordinates Representation,”
IEICE-ED, 2020. [[paper]](https://www.jstage.jst.go.jp/article/transinf/E103.D/6/E103.D_2019MVP0009/_pdf/-char/ja)
1. <u>西村仁志</u>, 田坂和之, 川西康友, 村瀬洋,
“複数の相関フィルタを用いた見えの変化に頑健な物体追跡,”
映像情報メディア学会誌, 2019. (Best paper) [[paper]](https://www.jstage.jst.go.jp/article/itej/73/5/73_1004/_pdf/-char/ja)
1. H. Sabirin, <u>H. Nishimura</u>, and S. Naito,
“Synchronized Tracking in Multiple Omnidirectional Cameras with Overlapping View,”
IEICE-ED, 2019. [[paper]](https://www.jstage.jst.go.jp/article/transinf/E102.D/11/E102.D_2018EDP7305/_pdf/-char/ja)
1. <u>西村仁志</u>, 小篠裕子, 有木康雄, 中野幹生,
“一般物体認識に基づく音声で指示された物体の選択法,”
電子情報通信学会論文誌D, 2015. [[paper]](https://search.ieice.org/bin/pdf_link.php?category=D&lang=J&year=2015&fname=j98-d_9_1265&abst=)

## International Conference
1. <u>H. Nishimura</u>, H. Kato, and K. Kawamura,
“Arithmetic Coding of Displacements in Dynamic Meshes with Bypass Mode for Complexity Reduction,”
Proc. VCIP, 2023. [paper]
1. <u>H. Nishimura</u>, H. Kato, and K. Kawamura,
“HIERARCHICAL ARITHMETIC CODING OF DISPLACEMENTS FOR DYNAMIC MESH COMPRESSION,”
Proc. ICIP, 2023. [paper]
1. <u>H. Nishimura</u>, Y. Nagai, K. Tasaka, and H. Yanagihara,
“Object Tracking by Branched Correlation Filters and Particle Filter,”
Proc. ACPR, 2017. [[paper]](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8575803)
1. <u>H. Nishimura</u>, Y. Ozasa, Y. Ariki, and M. Nakano,
“Selection of an Object Requested by Speech Based on Generic Object Recognition,”
Proc. ICMI Workshop on MMRWHRI, 2014. [[paper]](http://delivery.acm.org/10.1145/2670000/2666505/p23-nishimura.pdf?ip=192.26.91.225&id=2666505&acc=ACTIVE%20SERVICE&key=2D77E7682F10D892%2E2D77E7682F10D892%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&__acm__=1568865809_46c1b464b7777d0f3f414c1f021a4251)
1. <u>H. Nishimura</u>, Y. Ozasa, Y. Ariki, and M. Nakano,
“Selection of Unknown Objects Specifed by Speech Using Models Constructed from Web Images,”
Proc. ICPR, 2014. [[paper]](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6976802)
1. <u>H. Nishimura</u>, Y. Ozasa, Y. Ariki, and M. Nakano,
“Object Recognition by Integrated Information Using Web Images,”
Proc. ACPR, 2013. [[paper]](http://www.me.cs.scitec.kobe-u.ac.jp/publications/papers/2013/ACPR2013_nishimura.pdf)

## Domestic Conference (Japanese)
1. <u>西村仁志</u>, 披田野清良, 黒川茂莉,
“拡散モデルによる動画データのプライバシー保護に向けて,”
画像センシングシンポジウム, 2024.
1. <u>H. Nishimura</u>, H. Kato, K. Kawamura,
“A Study on Residual Quantization in Displacement Coding of Dynamic Meshes,”
AVM研究発表会, 2024.
1. 明堂絵美, <u>西村仁志</u>, 河村圭,
“動的メッシュ圧縮におけるLoDベース変位量並び替えに関する検討,”
映像情報メディア学会メディア工学研究会, 2023.
1. <u>西村仁志</u>, 加藤晴久, 河村圭,
“動的メッシュ圧縮における変位量の量子化タイミングに関する検討,”
FIT, 2023.
1. 川西康友, 村瀬洋, <u>西村仁志</u>, 内藤整,
“姿勢の時間変化パターンを考慮した超低解像度画像系列中の人物姿勢推定,”
画像の認識・理解シンポジウム, 2023.
1. <u>西村仁志</u>, 河村圭,
“動的メッシュ圧縮のための変位量のコンテキスト適応型2値算術符号化,”
映像情報メディア学会冬季大会, 2022.
1. <u>西村仁志</u>, 河村圭,
“動的メッシュ圧縮における変位量のコンテキスト適応型算術符号化,”
画像符号化シンポジウム/映像メディア処理シンポジウム, 2022.
1. <u>H. Nishimura</u>, S. Komorita, Y. Kawanishi, and H. Murase,
“Fast and Accurate Multiple Human Tracking by Skipped-Detection and Optical-Flow,”
画像の認識・理解シンポジウム, 2022.
1. 岡田純京, <u>西村仁志</u>, 小篠裕子,
“ハイパースペクトルカメラによる物体追跡の問題点に関する分析,”
情報処理学会全国大会, 2022.
1. <u>西村仁志</u>, 小森田賢史, 川西康友, 村瀬洋,
“低フレームレート物体検出と高フレームレート特徴点追跡の統合による高速・高精度な複数物体追跡,”
画像の認識・理解シンポジウム, 2021.
1. <u>西村仁志</u>, 田坂和之, 川西康友, 村瀬洋,
“基本行動特徴量を用いたオンライン複数人物追跡,”
画像符号化シンポジウム/映像メディア処理シンポジウム, 2019.
1. <u>西村仁志</u>, 田坂和之, 川西康友, 村瀬洋,
“人物検出と行動認識を統合したオンライン時空間行動検出手法の検討,”
映像情報メディア学会冬季大会, 2018.
1. J. Xu, K. Oniki, <u>H. Nishimura</u>, and K. Tasaka,
“A Study on Detection of Kicking Motions in Multi-view 4K Soccer Videos,”
画像符号化シンポジウム/映像メディア処理シンポジウム, 2018.
1. <u>西村仁志</u>, 永井有希, 小林達也, 酒澤茂之,
“相関フィルタを用いた確率的状態推定による長時間物体追跡,”
画像の認識・理解シンポジウム, 2017.
1. <u>西村仁志</u>, 永井有希, 小林達也, 酒澤茂之,
“カーネル化相関フィルタを用いた確率的運動予測に基づく物体追跡法,”
映像情報メディア学会冬季大会, 2016.
1. <u>西村仁志</u>, 小篠裕子, 有木康雄, 中野幹生,
“Web 画像を用いた一般物体認識と指示発話の音声認識を統合した物体選択法,”
画像の認識・理解シンポジウム, 2014.
1. <u>H. Nishimura</u>, Y. Ozasa, Y. Ariki, and M. Nakano,
“Object Recognition by Integrated Information Using Speech and Web Images,”
画像の認識・理解シンポジウム, 2013.
1. <u>西村仁志</u>, 小篠裕子, 有木康雄, 中野幹生,
“Web 画像を用いたマルチモーダル情報による物体認識,”
電子情報通信学会総合大会, 2013.

## Others
1. <u>西村仁志</u>,
“広域撮影可能な監視カメラを用いた人物追跡,”
特集「人工知能分野における博士論文」, 人工知能学会誌, 2022.
1. <u>H. Nishimura</u>, S. Komorita, Y. Kawanishi, and H. Murase,
“SDOF-Tracker: Fast and Accurate Multiple Human Tracking by Skipped-Detection and Optical-Flow,”
arXiv:2106.14259, 2021. [[paper]](https://arxiv.org/abs/2106.14259) [[code]](https://github.com/hitottiez/sdof-tracker)
1. <u>西村仁志</u>, 田坂和之, 川西康友, 村瀬洋,
“複数の相関フィルタを用いた見えの変化に頑健な物体追跡,”
映像情報メディア学会誌 研究ハイライト, 2020.
1. <u>H. Nishimura</u>, K. Tasaka, Y. Kawanishi, and H. Murase,
“Multiple Human Tracking using Multi-Cues including Primitive Action Features,”
arXiv:1909.08171, 2019. [[paper]](http://arxiv.org/abs/1909.08171) [[code]](https://github.com/hitottiez/mht-paf)

# Article
1. 徐建鋒, <u>西村仁志</u>, 岸本広輝,
“技術解説：動的メッシュ符号化の標準化,”
映像情報メディア学会誌, 2024.

# Patent
1. “メッシュ復号装置、メッシュ復号方法及びプログラム,”
特願2024-065030, 2024.
1. “メッシュ復号装置、メッシュ復号方法及びプログラム,”
特願2024-065029, 2024.
1. “メッシュ復号装置、メッシュ復号方法及びプログラム,”
特願2024-064880, 2024.
1. “メッシュ復号装置、メッシュ復号方法及びプログラム,”
特願2024-046822, 2023.
1. “メッシュ復号装置、メッシュ復号方法及びプログラム,”
特願2024-046821, 2023.
1. “メッシュ復号装置、メッシュ復号方法及びプログラム,”
特願2023-171969, 2023.
1. “メッシュ復号装置、メッシュ復号方法及びプログラム,”
特願2023-171968, 2023.
1. “メッシュ復号装置、メッシュ復号方法及びプログラム,”
特願2023-109440, 2023.
1. “メッシュ復号装置、メッシュ復号方法及びプログラム,”
特願2023-109439, 2023.
1. “メッシュ復号装置、メッシュ復号方法及びプログラム,”
特願2023-112559, 2023.
1. “メッシュ復号装置、メッシュ復号方法及びプログラム,”
特願2023-111752, 2023.
1. “メッシュ復号装置、メッシュ復号方法及びプログラム,”
特願2023-066596, 2023.
1. “メッシュ復号装置、メッシュ復号方法及びプログラム,”
特願2023-066595, 2023.
1. “メッシュ復号装置、メッシュ復号方法及びプログラム,”
特願2022-212452, 2022.
1. “メッシュ復号装置、メッシュ復号方法及びプログラム,”
特願2022-212451, 2022.
1. “メッシュ復号装置、メッシュ符号化装置、メッシュ復号方法及びプログラム,”
特願2022-165086, 2022.
1. “メッシュ復号装置、メッシュ符号化装置、メッシュ復号方法及びプログラム,”
特願2022-110865, 2022.
1. “メッシュ復号装置、メッシュ符号化装置、メッシュ復号方法及びプログラム,”
特願2022-110864, 2022.
1. “予め決定した主体対象の経路を利用する経路予測モデル、プログラム、装置及び方法,”
特願2022-077409, 2022.
1. “物体追跡装置及びプログラム,”
特願2021-096895, 2021.
1. “オブジェクト追跡装置及びオブジェクト追跡方法,”
特願2020-009676, 2020.
1. “人物を追跡する映像解析装置、プログラム及び方法,”
特願2018-228581, 2018.
1. “変化点で複数候補を考慮して物体を追跡する装置、プログラム及び方法,”
特願2018-062972, 2018.
1. “オブジェクト追跡装置、オブジェクト追跡方法、及びオブジェクト追跡プログラム,”
特願2017-105746, 2017.
1. “変化点で複数候補を考慮して物体を追跡する装置、プログラム及び方法,”
特願2016-221019, 2016.

# SNS
[Twitter](https://twitter.com/hitottiez), 
[Facebook](https://www.facebook.com/hitoshi.nishimura.75), 
[Ameba blog](https://ameblo.jp/hitotties/), 
[Github](https://github.com/hitottiez), 
[Qiita](https://qiita.com/hitottiez), 
[SlideShare](https://www.slideshare.net/hitoshinishimura75), 
[Google Scholar](https://scholar.google.co.jp/citations?user=iIHuJfUAAAAJ&hl=ja&oi=sra)
